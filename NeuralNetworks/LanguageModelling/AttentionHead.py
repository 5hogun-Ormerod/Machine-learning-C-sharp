# -*- coding: utf-8 -*-
from torch import nn
import torch

class Attention(nn.Module):
    
    def __init__(self, dimension):
        super.__init__
    
    
    def forward(self, X):
        pass
    