# -*- coding: utf-8 -*-
from torch import nn
import torch

class Attention(nn.Module):
    
    def __init__(self, dimensions):
        super(Attention, self).__init__()
        
    
    def forward(self, X):
        pass
    